{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e090a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random, hashlib, json\n",
    "from math import floor\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e93e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SRC = Path(r\"D:\\ClassRoom\\ComputerVision\\Image_processing\\Dataset\")             # source folder\n",
    "DST = Path(r\"D:\\ClassRoom\\ComputerVision\\Image_processing\\Dataset_preprocessed\")# destination\n",
    "TARGET_SIZE = 300\n",
    "RESIZE_METHOD = \"pad\"   # \"pad\" or \"center_crop\"\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.2\n",
    "TEST_RATIO = 0.1\n",
    "SEED = 42\n",
    "COPY_FILES = True\n",
    "DEDUP = True\n",
    "DRYRUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e46f14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preprocess (fixed). SRC: D:\\ClassRoom\\ComputerVision\\Dataset DST: D:\\ClassRoom\\ComputerVision\\Dataset_preprocessed\n",
      "Detected layout: split\n",
      "Wrote CSVs and dataset_stats.json\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "VALID_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "\n",
    "def is_image_file(p: Path): return p.is_file() and p.suffix.lower() in VALID_EXTS\n",
    "\n",
    "def safe_open_image(path: Path):\n",
    "    try:\n",
    "        with Image.open(path) as im: im.verify()\n",
    "        im = Image.open(path); im.load(); return im\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def compute_hash(path: Path, chunk_size=8192):\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        while True:\n",
    "            chunk = f.read(chunk_size)\n",
    "            if not chunk: break\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def resize_with_aspect(img: Image.Image, target_size: int, method: str = \"pad\"):\n",
    "    if img.mode != \"RGB\": img = img.convert(\"RGB\")\n",
    "    w, h = img.size\n",
    "    if method == \"center_crop\":\n",
    "        ratio = max(target_size / w, target_size / h)\n",
    "        nw, nh = int(w * ratio + 0.5), int(h * ratio + 0.5)\n",
    "        img_resized = img.resize((nw, nh), Image.LANCZOS)\n",
    "        left = (nw - target_size) // 2; top = (nh - target_size) // 2\n",
    "        return img_resized.crop((left, top, left + target_size, top + target_size))\n",
    "    else:\n",
    "        img.thumbnail((target_size, target_size), Image.LANCZOS)\n",
    "        new_img = Image.new(\"RGB\", (target_size, target_size), (0, 0, 0))\n",
    "        left = (target_size - img.width) // 2; top = (target_size - img.height) // 2\n",
    "        new_img.paste(img, (left, top)); return new_img\n",
    "\n",
    "def ensure_dir(p: Path): p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def deterministic_split(items, tr, vr, te, seed):\n",
    "    n = len(items)\n",
    "    if n == 0: return [], [], []\n",
    "    rnd = random.Random(seed); items_shuf = items[:]; rnd.shuffle(items_shuf)\n",
    "    n_train = int(floor(n * tr)); n_val = int(floor(n * vr)); n_test = n - n_train - n_val\n",
    "    if n_train == 0 and n >= 1:\n",
    "        n_train = 1\n",
    "        if n_test > 0: n_test -= 1\n",
    "        elif n_val > 0: n_val -= 1\n",
    "    t1 = n_train; t2 = n_train + n_val\n",
    "    return items_shuf[:t1], items_shuf[t1:t2], items_shuf[t2:]\n",
    "\n",
    "def discover_layout(src: Path):\n",
    "    \"\"\"Detect if source already has train/val/test split.\"\"\"\n",
    "    lower_children = {p.name.lower(): p for p in src.iterdir() if p.is_dir()}\n",
    "    has_splits = all(k in lower_children for k in (\"train\",\"val\",\"test\"))\n",
    "    return \"split\" if has_splits else \"unsplit\"\n",
    "\n",
    "def process_existing_splits(src: Path, dst: Path, seen_hashes, copy_files, dedup, dryrun):\n",
    "    manifest = {\"train\": [], \"val\": [], \"test\": []}\n",
    "    stats = {}\n",
    "    for split in (\"train\",\"val\",\"test\"):\n",
    "        split_src = src / split\n",
    "        if not split_src.exists(): continue\n",
    "        for cls in sorted([p for p in split_src.iterdir() if p.is_dir()], key=lambda x: x.name):\n",
    "            imgs = [p for p in cls.iterdir() if is_image_file(p)]\n",
    "            valid = []\n",
    "            for p in imgs:\n",
    "                im = safe_open_image(p)\n",
    "                if im is None:\n",
    "                    print(f\"Skipping corrupted: {p}\")\n",
    "                    continue\n",
    "                if dedup:\n",
    "                    h = compute_hash(p)\n",
    "                    if h in seen_hashes:\n",
    "                        continue\n",
    "                    seen_hashes.add(h)\n",
    "                valid.append(p)\n",
    "            stats.setdefault(cls.name, {\"total\":0,\"train\":0,\"val\":0,\"test\":0})\n",
    "            stats[cls.name][\"total\"] += len(valid)\n",
    "            # process each valid image into dst/<split>/<class>\n",
    "            out_class = dst / split / cls.name; ensure_dir(out_class)\n",
    "            for p in valid:\n",
    "                if dryrun:\n",
    "                    manifest[split].append({\"filepath\": str((out_class / p.name).resolve()), \"class\": cls.name})\n",
    "                    continue\n",
    "                try:\n",
    "                    im = Image.open(p).convert(\"RGB\")\n",
    "                except Exception:\n",
    "                    continue\n",
    "                proc = resize_with_aspect(im, TARGET_SIZE, method=RESIZE_METHOD)\n",
    "                out_path = out_class / p.name\n",
    "                if out_path.exists():\n",
    "                    base = p.stem; ext = p.suffix.lower(); i = 1\n",
    "                    while (out_class / f\"{base}_{i}{ext}\").exists(): i+=1\n",
    "                    out_path = out_class / f\"{base}_{i}{ext}\"\n",
    "                proc.save(out_path, quality=95)\n",
    "                if not copy_files:\n",
    "                    try: p.unlink()\n",
    "                    except Exception: pass\n",
    "                manifest[split].append({\"filepath\": str(out_path.resolve()), \"class\": cls.name})\n",
    "            # count split counts\n",
    "            stats[cls.name][split] += len(valid)\n",
    "    return manifest, stats\n",
    "\n",
    "def process_unsplit(src: Path, dst: Path, seen_hashes, copy_files, dedup, dryrun):\n",
    "    manifest = {\"train\": [], \"val\": [], \"test\": []}\n",
    "    stats = {}\n",
    "    class_dirs = sorted([p for p in src.iterdir() if p.is_dir()], key=lambda x: x.name)\n",
    "    for cls in class_dirs:\n",
    "        imgs = [p for p in cls.iterdir() if is_image_file(p)]\n",
    "        valid = []\n",
    "        for p in imgs:\n",
    "            im = safe_open_image(p)\n",
    "            if im is None:\n",
    "                print(f\"Skipping corrupted: {p}\")\n",
    "                continue\n",
    "            if dedup:\n",
    "                h = compute_hash(p)\n",
    "                if h in seen_hashes:\n",
    "                    continue\n",
    "                seen_hashes.add(h)\n",
    "            valid.append(p)\n",
    "        tr, va, te = deterministic_split(valid, TRAIN_RATIO, VAL_RATIO, TEST_RATIO, SEED + hash(cls.name) & 0xffffffff)\n",
    "        stats[cls.name] = {\"total\": len(valid), \"train\": len(tr), \"val\": len(va), \"test\": len(te)}\n",
    "        for split_name, lst in ((\"train\",tr),(\"val\",va),(\"test\",te)):\n",
    "            out_class = dst / split_name / cls.name; ensure_dir(out_class)\n",
    "            for p in lst:\n",
    "                if dryrun:\n",
    "                    manifest[split_name].append({\"filepath\": str((out_class / p.name).resolve()), \"class\": cls.name})\n",
    "                    continue\n",
    "                try:\n",
    "                    im = Image.open(p).convert(\"RGB\")\n",
    "                except Exception:\n",
    "                    continue\n",
    "                proc = resize_with_aspect(im, TARGET_SIZE, method=RESIZE_METHOD)\n",
    "                out_path = out_class / p.name\n",
    "                if out_path.exists():\n",
    "                    base = p.stem; ext = p.suffix.lower(); i = 1\n",
    "                    while (out_class / f\"{base}_{i}{ext}\").exists(): i+=1\n",
    "                    out_path = out_class / f\"{base}_{i}{ext}\"\n",
    "                proc.save(out_path, quality=95)\n",
    "                if not copy_files:\n",
    "                    try: p.unlink()\n",
    "                    except Exception: pass\n",
    "                manifest[split_name].append({\"filepath\": str(out_path.resolve()), \"class\": cls.name})\n",
    "    return manifest, stats\n",
    "\n",
    "def compute_mean_std(manifest_train):\n",
    "    mean = np.zeros(3, dtype=np.float64); sq = np.zeros(3, dtype=np.float64); count = 0\n",
    "    for row in manifest_train:\n",
    "        p = Path(row[\"filepath\"])\n",
    "        try:\n",
    "            im = Image.open(p).convert(\"RGB\")\n",
    "            arr = np.asarray(im, dtype=np.float32)/255.0\n",
    "            pixels = arr.shape[0]*arr.shape[1]\n",
    "            mean += arr.reshape(-1,3).sum(axis=0)\n",
    "            sq += (arr.reshape(-1,3)**2).sum(axis=0)\n",
    "            count += pixels\n",
    "        except Exception:\n",
    "            continue\n",
    "    if count>0:\n",
    "        mean = (mean/count).tolist()\n",
    "        var = (sq/count) - np.array(mean)**2\n",
    "        std  = np.sqrt(np.maximum(var,1e-12)).tolist()\n",
    "    else:\n",
    "        mean = [0.485,0.456,0.406]; std=[0.229,0.224,0.225]\n",
    "    return mean, std\n",
    "\n",
    "def write_csvs_and_stats(dst: Path, manifest, stats, mean, std, src):\n",
    "    import csv\n",
    "    for split in (\"train\",\"val\",\"test\"):\n",
    "        csv_path = dst / f\"{split}.csv\"\n",
    "        with open(csv_path,\"w\",newline=\"\",encoding=\"utf8\") as f:\n",
    "            writer = csv.writer(f); writer.writerow([\"filepath\",\"class\"])\n",
    "            for r in manifest[split]:\n",
    "                writer.writerow([r[\"filepath\"], r[\"class\"]])\n",
    "    stats_out = {\n",
    "        \"source\": str(src.resolve()), \"destination\": str(dst.resolve()),\n",
    "        \"target_size\": TARGET_SIZE, \"resize_method\": RESIZE_METHOD,\n",
    "        \"ratios\": {\"train\": TRAIN_RATIO,\"val\":VAL_RATIO,\"test\":TEST_RATIO},\n",
    "        \"classes\": stats, \"train_mean\": mean, \"train_std\": std\n",
    "    }\n",
    "    with open(dst / \"dataset_stats.json\",\"w\",encoding=\"utf8\") as f: json.dump(stats_out,f,indent=2)\n",
    "    print(\"Wrote CSVs and dataset_stats.json\")\n",
    "\n",
    "def main():\n",
    "    print(\"Start preprocess (fixed). SRC:\", SRC, \"DST:\", DST)\n",
    "    ensure_dir = lambda p: p.mkdir(parents=True, exist_ok=True)\n",
    "    if not SRC.exists() or not SRC.is_dir():\n",
    "        print(\"Invalid SRC\"); return\n",
    "    ensure_dir(DST)\n",
    "    layout = discover_layout(SRC)\n",
    "    print(\"Detected layout:\", layout)\n",
    "    seen_hashes = set()\n",
    "    if DRYRUN:\n",
    "        print(\"DRYRUN: printing planned actions only\")\n",
    "    if layout == \"split\":\n",
    "        manifest, stats = process_existing_splits(SRC, DST, seen_hashes, COPY_FILES, DEDUP, DRYRUN)\n",
    "    else:\n",
    "        manifest, stats = process_unsplit(SRC, DST, seen_hashes, COPY_FILES, DEDUP, DRYRUN)\n",
    "    mean, std = compute_mean_std(manifest[\"train\"])\n",
    "    write_csvs_and_stats(DST, manifest, stats, mean, std, SRC)\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
